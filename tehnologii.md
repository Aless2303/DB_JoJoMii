# ğŸ“š DocumentaÈ›ie CompletÄƒ - 3 Proiecte AI Hackathon

Acest document analizeazÄƒ Ã®n detaliu cele 3 proiecte de hackathon È™i oferÄƒ un **tutorial step-by-step** pentru a reproduce modul Ã®n care s-au implementat soluÈ›iile AI.

---

## ğŸ“‹ Cuprins

1. [Rezumat Tehnologii](#-rezumat-tehnologii)
2. [Proiect 1: Innovative4AI (PROXITY)](#-proiect-1-innovative4ai-proxity---nyc-business-simulator)
3. [Proiect 2: NEXXT_AI_PROJECT](#-proiect-2-nexxt_ai_project---customer-retention-intelligence)
4. [Proiect 3: SpaceFlow](#-proiect-3-spaceflow---room-booking-system)
5. [Workflow-uri Comune](#-workflow-uri-comune)
6. [Tutorial Step-by-Step](#-tutorial-step-by-step-pentru-implementare)
7. [Patterns È™i Best Practices](#-patterns-È™i-best-practices)

---

## ğŸ”§ Rezumat Tehnologii

| Tehnologie | Innovative4AI | NEXXT_AI | SpaceFlow |
|------------|---------------|----------|-----------|
| **Vercel AI SDK** | âœ… DA (`ai` package) | âŒ NU | âŒ NU |
| **OpenAI SDK** | âœ… DA (`@ai-sdk/openai`) | âœ… DA (via LiteLLM) | âœ… DA (direct) |
| **OpenAI Agents SDK** | âŒ NU | âœ… DA (`openai-agents`) | âŒ NU |
| **LiteLLM** | âŒ NU | âœ… DA | âŒ NU |
| **AWS Bedrock** | âŒ NU | âœ… DA (Claude 4.5) | âŒ NU |
| **MCP (Model Context Protocol)** | âŒ NU | âœ… DA | âŒ NU |
| **RAG (Vector DB)** | âœ… DA (Qdrant) | âŒ NU | âŒ NU |
| **Structured Output (Zod)** | âœ… DA | âœ… DA (Pydantic) | âœ… DA (Pydantic) |
| **Multi-Agent System** | âœ… DA (9 agenÈ›i) | âœ… DA (13 agenÈ›i) | âŒ NU (1 agent) |

---

## ğŸ™ï¸ Proiect 1: Innovative4AI (PROXITY) - NYC Business Simulator

### ğŸ“ Descriere
PlatformÄƒ AI de simulare business care modeleazÄƒ scenarii antreprenoriale Ã®n NYC. FoloseÈ™te date US Census, Google Trends È™i **9 agenÈ›i AI specializaÈ›i** pentru a genera prognoze lunare de performanÈ›Äƒ.

### ğŸ› ï¸ Stack Tehnologic

**Frontend:**
- React 18 + Vite + TypeScript
- TanStack Query (server state)
- Mapbox GL JS (hÄƒrÈ›i interactive)
- Recharts (vizualizÄƒri)
- Tailwind CSS + shadcn/ui

**Backend:**
- FastAPI + Python
- SQLAlchemy + PostgreSQL
- US Census API
- Google Trends API (pytrends)

**Agents Orchestrator (IMPORTANT - foloseÈ™te Vercel AI SDK):**
- **Next.js 14** (API routes)
- **Vercel AI SDK** (`ai` package v5.0.93)
- **@ai-sdk/openai** (v2.0.67)
- **Zod** pentru structured output
- **Qdrant** pentru RAG

### ğŸ¤– Arhitectura Multi-Agent

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR (Next.js)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 0: RAG Retrieval (Qdrant)                    ~0.5s   â”‚
â”‚  PHASE 1: Market Context Agent (GPT-4-mini)         ~1s     â”‚
â”‚  PHASE 2: Events + Trends Agents (PARALLEL)         ~2s     â”‚
â”‚  PHASE 3: Supplier + Competition + Employee (PARALLEL) ~1.5sâ”‚
â”‚  PHASE 4: Customer Simulation Agent                  ~2s     â”‚
â”‚  PHASE 5: Financial + Report Agents (PARALLEL)      ~3s     â”‚
â”‚  PHASE 6: RAG Storage                               ~0.2s   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    TOTAL: ~10 secunde/lunÄƒ simulatÄƒ
```

### ğŸ“„ Cum au implementat AI-ul

#### 1. Instalare dependenÈ›e (package.json)
```json
{
  "dependencies": {
    "@ai-sdk/openai": "^2.0.67",
    "@ai-sdk/anthropic": "^2.0.44",
    "@qdrant/js-client-rest": "^1.15.1",
    "ai": "^5.0.93",
    "zod": "^3.23.0",
    "next": "^14.2.0"
  }
}
```

#### 2. Pattern-ul de Agent cu Vercel AI SDK

**FiÈ™ier: `lib/simulation_agents/market-context-agent.ts`**

```typescript
import { openai } from '@ai-sdk/openai';
import { generateObject } from 'ai';
import { z } from 'zod';

// 1. DefineÈ™ti schema cu Zod
export const MarketContextSchema = z.object({
  economic_climate: z.enum(['recession', 'stable', 'growth']),
  industry_saturation: z.number().min(0).max(100),
  market_demand_score: z.number(),
  seasonal_multiplier: z.number(),
  insights: z.string()
});

// 2. FuncÈ›ia agentului
export async function analyzeMarketContext(
  businessType: string,
  location: { neighborhood: string },
  censusData: DetailedCensusData,
  survivalData: SurvivalData | null,
  currentMonth: number,
  currentYear: number
): Promise<z.infer<typeof MarketContextSchema>> {
  
  // Calcule matematice ÃNAINTE de LLM
  const industrySaturation = calculateIndustrySaturation(...);
  const economicClimate = calculateEconomicClimate(...);
  
  // 3. Apel LLM cu generateObject pentru structured output
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: MarketContextSchema,
    prompt: `
      Analyze market conditions for a ${businessType} in ${location.neighborhood}.
      
      Census Data:
      - Population: ${censusData.total_population}
      - Median Income: ${censusData.median_income}
      
      Pre-calculated metrics:
      - Industry Saturation: ${industrySaturation}%
      - Economic Climate: ${economicClimate}
      
      Provide market insights...
    `,
    temperature: 0.7,
  });

  return object;
}
```

#### 3. RAG Service cu Qdrant + Vercel AI SDK

**FiÈ™ier: `lib/services/rag-service.ts`**

```typescript
import { QdrantClient } from '@qdrant/js-client-rest';
import { openai } from '@ai-sdk/openai';
import { embed } from 'ai';

const qdrant = new QdrantClient({ host: 'localhost', port: 6333 });

// Generare embedding cu Vercel AI SDK
export async function storeSimulationState(
  userId: string,
  businessId: string,
  month: number,
  stateSummary: SimulationStateSummary
): Promise<void> {
  
  const summaryText = createStateSummaryText(stateSummary);
  
  // FoloseÈ™te `embed` din Vercel AI SDK
  const { embedding } = await embed({
    model: openai.embedding('text-embedding-3-small'),
    value: summaryText,
  });
  
  await qdrant.upsert('simulation_states', {
    points: [{
      id: `${userId}_${businessId}_month${month}`,
      vector: embedding,
      payload: {
        user_id: userId,
        business_id: businessId,
        month: month,
        revenue: stateSummary.revenue,
        profit: stateSummary.profit,
        // ... alte date
      }
    }]
  });
}

// Retrieve cu semantic search
export async function retrieveHistoricalContext(
  userId: string,
  businessId: string,
  currentMonth: number,
  limit: number = 3
): Promise<HistoricalContext> {
  
  const queryText = `Business state for month ${currentMonth}`;
  
  const { embedding } = await embed({
    model: openai.embedding('text-embedding-3-small'),
    value: queryText,
  });
  
  const results = await qdrant.search('simulation_states', {
    vector: embedding,
    limit: limit,
    filter: {
      must: [
        { key: 'user_id', match: { value: userId } },
        { key: 'business_id', match: { value: businessId } }
      ]
    }
  });
  
  return {
    recent_months: results.map(r => r.payload),
    similar_situations: [],
    past_recommendations: []
  };
}
```

#### 4. Orchestratorul - ExecuÈ›ie ParalelizatÄƒ

**FiÈ™ier: `core/orchestrator.ts`**

```typescript
export async function runMonthlySimulation(input: SimulationInput): Promise<SimulationOutput> {
  
  // PHASE 0: RAG Retrieval
  const historicalContext = await retrieveHistoricalContext(
    input.userId, input.businessId, input.currentMonth, 3
  );
  
  // PHASE 1: Market Context (sequential)
  const marketContext = await analyzeMarketContext(...);
  
  // PHASE 2: External Analysis (PARALLEL)
  const [eventsData, trendsData] = await Promise.all([
    generateBusinessEvent(...),
    analyzeTrendsForBusiness(...),
  ]);
  
  // PHASE 3: Market Dynamics (PARALLEL)
  const [supplierData, competitionData, employeeData] = await Promise.all([
    analyzeSupplierDynamics(...),
    analyzeCompetition(...),
    Promise.resolve(calculateEmployeeMetrics(...)), // Pure math, no LLM
  ]);
  
  // PHASE 4: Customer Simulation
  const customerData = await simulateCustomerBehavior(...);
  
  // PHASE 5: Reporting (PARALLEL)
  const [financialData, report] = await Promise.all([
    Promise.resolve(analyzeFinancialPerformance(...)), // Pure math
    generateMonthlyReport(...), // LLM-powered
  ]);
  
  // PHASE 6: RAG Storage
  await storeSimulationState(...);
  
  return { marketContext, eventsData, trendsData, ... };
}
```

#### 5. API Route Ã®n Next.js

**FiÈ™ier: `app/api/simulate/route.ts`**

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { runMonthlySimulation } from '@/core/orchestrator';

export async function POST(request: NextRequest) {
  const input = await request.json();
  
  const result = await runMonthlySimulation(input);
  
  return NextResponse.json(result);
}
```

---

## ğŸ¦ Proiect 2: NEXXT_AI_PROJECT - Customer Retention Intelligence

### ğŸ“ Descriere
Sistem AI pentru retenÈ›ia clienÈ›ilor Ã®n banking. FoloseÈ™te **13 agenÈ›i LLM specializaÈ›i** cu OpenAI Agents SDK È™i Claude 4.5 via AWS Bedrock.

### ğŸ› ï¸ Stack Tehnologic

**Frontend & UI:**
- **Streamlit** (Python web framework)
- st-annotated-text (highlighting)

**Backend & AI:**
- **OpenAI Agents SDK** (`openai-agents` v0.4.2)
- **LiteLLM** (model abstraction layer)
- **AWS Bedrock** (Claude 4.5 Sonnet)
- **MCP** (Model Context Protocol) pentru PostgreSQL
- **Pydantic** pentru validare

### ğŸ¤– Arhitectura 13 AgenÈ›i

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OPENAI AGENTS SDK FRAMEWORK                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚        ORCHESTRATOR AGENT (Coordinator)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚Profileâ”‚Contentâ”‚ Risk â”‚ Comms â”‚Productâ”‚Sentimentâ”‚    â”‚
â”‚  â”‚Agent â”‚Personaâ”‚Assess â”‚ Agent â”‚Recom â”‚Analysis â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚Engageâ”‚Financeâ”‚Transacâ”‚Lifecyâ”‚Retentâ”‚Feedbackâ”‚       â”‚
â”‚  â”‚Optim â”‚Health â”‚Patternâ”‚cleMgtâ”‚Strat â”‚Process â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                         â”‚
â”‚              â†“ LiteLLM Abstraction â†“                   â”‚
â”‚              AWS Bedrock (Claude 4.5)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“„ Cum au implementat AI-ul

#### 1. Instalare dependenÈ›e (requirements.txt)
```txt
openai-agents==0.4.2
litellm==1.79.0
mcp==1.20.0
boto3==1.40.64
streamlit==1.51.0
pydantic==2.12.3
```

#### 2. Configurare LiteLLM pentru AWS Bedrock

**FiÈ™ier: `src/config/settings.py`**

```python
import os
from dotenv import load_dotenv
from agents.extensions.models.litellm_model import LitellmModel

load_dotenv()

# Disable tracing
os.environ["AGENTS_TRACING_DISABLED"] = "true"
os.environ["LITELLM_TELEMETRY"] = "False"

# AWS Bedrock API Key
AWS_BEDROCK_API_KEY = os.getenv("AWS_BEARER_TOKEN_BEDROCK")

# Default model: Claude 4.5 Sonnet via Bedrock
DEFAULT_LITELLM_MODEL = os.getenv(
    "DEFAULT_LITELLM_MODEL",
    "global.anthropic.claude-sonnet-4-20250514-v1:0"
)

def build_default_litellm_model():
    """Return a LitellmModel configured for AWS Bedrock."""
    return LitellmModel(
        model=DEFAULT_LITELLM_MODEL, 
        api_key=AWS_BEDROCK_API_KEY
    )
```

#### 3. Pattern-ul de Agent cu OpenAI Agents SDK

**FiÈ™ier: `src/agents/product_recommendation_agent.py`**

```python
from agents import Agent, function_tool, Runner
from pydantic import BaseModel
from typing import List
from src.config.settings import build_default_litellm_model

# 1. DefineÈ™ti modele cu Pydantic
class UserProfile(BaseModel):
    marital_status: str | None = None
    annual_income: float | None = None
    age: int | None = None
    risk_tolerance: str | None = None
    financial_goals: list[str] = []

class ProductJustification(BaseModel):
    product_name: str
    relevance_score: float  # 0.0 to 1.0
    justification: str
    key_benefits: List[str]

# 2. DefineÈ™ti un tool (function_tool)
@function_tool
def get_user_profile(email: str) -> dict:
    """Retrieve user profile from database."""
    from src.utils.db import get_user_by_email
    return get_user_by_email(email)

@function_tool
def get_all_products() -> list:
    """Get all banking products from database."""
    from src.utils.db import get_all_products
    return get_all_products()

# 3. Creezi agentul cu OpenAI Agents SDK
product_justification_agent = Agent(
    name="Product Justification Agent",
    instructions="""
    You are a banking product expert. Analyze each product's relevance 
    for a specific user profile.
    
    Consider:
    - User's income and financial goals
    - Risk tolerance
    - Current life stage
    - Product benefits vs user needs
    
    Return a structured justification with relevance score (0-1).
    """,
    model=build_default_litellm_model(),
    tools=[get_user_profile, get_all_products],
)

# 4. Agent principal care foloseÈ™te sub-agentul ca tool
product_recommendation_agent = Agent(
    name="Product Recommendation Orchestrator",
    instructions="""
    Orchestrate product ranking by calling the justification agent 
    for each product. Return ranked list.
    """,
    model=build_default_litellm_model(),
    tools=[product_justification_agent.as_tool(
        tool_name="justify_product",
        tool_description="Analyze product relevance for user"
    )],
)

# 5. FuncÈ›ie pentru rulare
async def rank_products_for_profile(
    user_profile: UserProfile,
    products: list
) -> List[ProductJustification]:
    
    prompt = f"""
    User Profile: {user_profile.model_dump_json()}
    
    Products to analyze: {products}
    
    For each product, analyze relevance and return justification.
    """
    
    result = await Runner.run(product_recommendation_agent, prompt)
    return result.final_output
```

#### 4. MCP Server pentru PostgreSQL

**FiÈ™ier: `src/mcp-postgres/mcp_postgres/server.py`**

```python
from mcp import Server
from mcp.types import Tool
import psycopg

# MCP Server pentru acces read-only la PostgreSQL
server = Server()

@server.tool("sql_query")
async def sql_query(sql: str, params: dict = None) -> str:
    """Execute a read-only SQL query."""
    if not sql.strip().upper().startswith("SELECT"):
        raise ValueError("Only SELECT queries allowed")
    
    async with psycopg.connect(CONNECTION_STRING) as conn:
        async with conn.cursor() as cur:
            await cur.execute(sql, params)
            rows = await cur.fetchall()
            return json.dumps({"rows": rows})

@server.tool("sql_schema")
async def sql_schema(include_views: bool = True) -> str:
    """Get database schema information."""
    # ... implementare
```

#### 5. PaginÄƒ Streamlit

**FiÈ™ier: `pages/2_Product_Recommendations_Florea.py`**

```python
import streamlit as st
import asyncio
from agents import Runner
from src.agents.product_recommendation_agent import (
    rank_products_for_profile,
    UserProfile
)

st.title("ğŸ¯ Product Recommendations")

# Input utilizator
income = st.number_input("Annual Income (RON)", min_value=0)
risk = st.selectbox("Risk Tolerance", ["low", "medium", "high"])

if st.button("Get Recommendations"):
    profile = UserProfile(
        annual_income=income,
        risk_tolerance=risk
    )
    
    with st.spinner("AI analyzing products..."):
        # Run async Ã®n Streamlit
        results = asyncio.run(rank_products_for_profile(profile))
    
    for rec in results:
        st.markdown(f"### {rec.product_name}")
        st.progress(rec.relevance_score)
        st.write(rec.justification)
```

---

## ğŸ¢ Proiect 3: SpaceFlow - Room Booking System

### ğŸ“ Descriere
PlatformÄƒ de management È™i rezervare spaÈ›ii cu **AI Event Planner** care sugereazÄƒ camere bazat pe activitÄƒÈ›i. FoloseÈ™te OpenAI SDK direct (nu Vercel, nu Agents SDK).

### ğŸ› ï¸ Stack Tehnologic

**Frontend:**
- React 18 + TypeScript + Vite
- Shadcn/UI + Radix UI + Tailwind CSS
- React Three Fiber + Three.js (3D/2D maps)
- TanStack Query + React Hook Form + Zod

**Backend:**
- FastAPI + Python
- SQLAlchemy + PostgreSQL (async cu asyncpg)
- **OpenAI SDK** (v1.12.0) - direct, fÄƒrÄƒ wrapper
- JWT Authentication

### ğŸ¤– Arhitectura AI (Un singur agent)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EVENT SUGGESTION SERVICE               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚       AsyncOpenAI Client (gpt-4o-mini)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                               â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â–¼               â–¼               â–¼              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚  Parse   â”‚   â”‚  Suggest â”‚   â”‚ Fallback â”‚          â”‚
â”‚   â”‚  Prompt  â”‚   â”‚   Room   â”‚   â”‚  Logic   â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                         â”‚
â”‚  Input: Natural language prompt                         â”‚
â”‚  Output: Room suggestions with confidence scores        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“„ Cum au implementat AI-ul

#### 1. Instalare dependenÈ›e (requirements.txt)
```txt
openai==1.12.0
fastapi==0.115.0
sqlalchemy==2.0.36
asyncpg==0.30.0
pydantic==2.10.0
```

#### 2. Serviciu AI cu OpenAI SDK Direct

**FiÈ™ier: `app/crud/event_suggestion.py`**

```python
from openai import AsyncOpenAI
from pydantic import BaseModel, Field
from typing import List, Optional
import json

class RoomSuggestion(BaseModel):
    room_id: int
    room_name: str
    confidence_score: float = Field(..., ge=0.0, le=1.0)
    reasoning: str

class EventSuggestionService:
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.OPENAI_API_KEY,
            timeout=120.0
        )
    
    async def _parse_prompt_to_activities(
        self,
        prompt: str,
        booking_date: Optional[date] = None
    ) -> dict:
        """Parse natural language into structured activities."""
        
        system_prompt = """You are an event planning assistant.
        Parse the user's request into structured activities.
        
        Return JSON:
        {
            "booking_date": "YYYY-MM-DD",
            "activities": [
                {
                    "name": "Activity name",
                    "start_time": "HH:MM",
                    "end_time": "HH:MM",
                    "participants_count": 1,
                    "required_amenities": ["Projector"],
                    "preferences": "any preferences"
                }
            ]
        }
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt},
            ],
            temperature=0.6,
            max_tokens=900,
            response_format={"type": "json_object"},  # JSON mode
        )
        
        return json.loads(response.choices[0].message.content)
    
    async def _get_ai_room_suggestion(
        self,
        activity: ActivityRequest,
        available_rooms: List[Room]
    ) -> dict:
        """Get AI suggestion for best room."""
        
        rooms_context = self._prepare_rooms_context(available_rooms)
        
        system_prompt = """You are a room booking assistant.
        Select the best room based on:
        1. Capacity >= participants
        2. Required amenities present
        3. Activity type match
        
        Return JSON:
        {
            "suggested_room_id": <number>,
            "confidence_score": <0-1>,
            "reasoning": "<explanation>",
            "alternative_room_ids": [<numbers>]
        }
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Activity: {activity}\nRooms: {rooms_context}"},
            ],
            temperature=0.5,
            max_tokens=450,
            response_format={"type": "json_object"},
        )
        
        return json.loads(response.choices[0].message.content)
    
    def _fallback_room_selection(
        self,
        activity: ActivityRequest,
        available_rooms: List[Room]
    ) -> dict:
        """Fallback logic if AI fails."""
        # LogicÄƒ bazatÄƒ pe reguli simple
        suitable = [r for r in available_rooms 
                    if r.capacity >= activity.participants_count]
        
        if activity.required_amenities:
            suitable = [r for r in suitable 
                        if all(a in r.amenities for a in activity.required_amenities)]
        
        suitable.sort(key=lambda r: r.capacity)
        best = suitable[0] if suitable else available_rooms[0]
        
        return {
            "suggested_room_id": best.id,
            "confidence_score": 0.7,
            "reasoning": "Selected by capacity and amenities match",
            "alternative_room_ids": [r.id for r in suitable[1:4]]
        }
```

#### 3. API Route FastAPI

**FiÈ™ier: `app/api/routes/event_suggestions.py`**

```python
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from app.schemas.event_suggestion import (
    EventSuggestionRequest,
    EventSuggestionResponse
)
from app.crud.event_suggestion import event_suggestion_service

router = APIRouter()

@router.post("/suggest", response_model=EventSuggestionResponse)
async def get_event_suggestions(
    request: EventSuggestionRequest,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """Get AI-powered room suggestions."""
    
    suggestions = await event_suggestion_service.generate_suggestions(
        db=db,
        request=request,
        user_id=current_user.id
    )
    
    return suggestions
```

#### 4. Schema Pydantic

**FiÈ™ier: `app/schemas/event_suggestion.py`**

```python
from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import date, time

class ActivityRequest(BaseModel):
    name: str
    start_time: time
    end_time: time
    participants_count: int = 1
    required_amenities: List[str] = []
    preferences: Optional[str] = None

class EventSuggestionRequest(BaseModel):
    prompt: Optional[str] = None  # Natural language
    booking_date: Optional[date] = None
    activities: Optional[List[ActivityRequest]] = None

class RoomSuggestion(BaseModel):
    room_id: int
    room_name: str
    capacity: int
    amenities: List[str]
    confidence_score: float = Field(..., ge=0.0, le=1.0)
    reasoning: str

class ActivitySuggestion(BaseModel):
    activity_name: str
    start_time: time
    end_time: time
    suggested_room: RoomSuggestion
    alternative_rooms: List[RoomSuggestion] = []

class EventSuggestionResponse(BaseModel):
    suggestions: List[ActivitySuggestion]
    total_estimated_cost: float
```

---

## ğŸ”„ Workflow-uri Comune

### Pattern 1: Structured Output cu Schema

Toate 3 proiectele folosesc schemas pentru output structurat:

| Proiect | Tehnologie | Exemplu |
|---------|------------|---------|
| Innovative4AI | Zod + `generateObject` | `MarketContextSchema.parse(...)` |
| NEXXT_AI | Pydantic | `ProductJustification.model_validate(...)` |
| SpaceFlow | Pydantic + JSON mode | `response_format={"type": "json_object"}` |

### Pattern 2: Prompt Engineering

Toate proiectele folosesc:
1. **System prompt** - defineÈ™te rolul È™i comportamentul
2. **User prompt** - conÈ›ine date specifice
3. **Context** - date din database/API externe

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           SYSTEM PROMPT                  â”‚
â”‚  - Rol: "You are a banking expert..."   â”‚
â”‚  - Reguli: "Return only JSON..."        â”‚
â”‚  - Format: Schema definition            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           USER PROMPT                    â”‚
â”‚  - Date utilizator                      â”‚
â”‚  - Context din DB                       â”‚
â”‚  - Ãntrebare specificÄƒ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    =
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        STRUCTURED OUTPUT                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pattern 3: Fallback Logic

SpaceFlow È™i Innovative4AI implementeazÄƒ fallback cÃ¢nd AI eÈ™ueazÄƒ:

```python
async def get_suggestion(...):
    try:
        # Try AI first
        return await self._get_ai_suggestion(...)
    except Exception as e:
        # Fallback to rule-based logic
        return self._fallback_selection(...)
```

### Pattern 4: Paralelizare

Innovative4AI foloseÈ™te `Promise.all()` pentru agenÈ›i independenÈ›i:

```typescript
// TypeScript (Next.js)
const [events, trends] = await Promise.all([
    generateBusinessEvent(...),
    analyzeTrendsForBusiness(...)
]);
```

---

## ğŸ“ Tutorial Step-by-Step pentru Implementare

### OpÈ›iunea A: Vercel AI SDK (ca Innovative4AI)

**CÃ¢nd sÄƒ foloseÈ™ti:** CÃ¢nd vrei structured output cu schema validation + streaming.

```bash
# 1. Init proiect Next.js
npx create-next-app@latest my-ai-app --typescript

# 2. Instalare dependenÈ›e
npm install ai @ai-sdk/openai zod

# 3. Setare variabile de mediu
echo "OPENAI_API_KEY=sk-..." > .env.local
```

**Cod minimal:**
```typescript
// lib/agents/my-agent.ts
import { openai } from '@ai-sdk/openai';
import { generateObject } from 'ai';
import { z } from 'zod';

const MySchema = z.object({
  answer: z.string(),
  confidence: z.number().min(0).max(1)
});

export async function myAgent(question: string) {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: MySchema,
    prompt: `Answer: ${question}`
  });
  return object;
}
```

### OpÈ›iunea B: OpenAI Agents SDK (ca NEXXT_AI)

**CÃ¢nd sÄƒ foloseÈ™ti:** CÃ¢nd ai nevoie de multi-agent orchestration cu tools.

```bash
# 1. Init proiect Python
mkdir my-agents && cd my-agents
python -m venv venv && source venv/bin/activate

# 2. Instalare
pip install openai-agents litellm pydantic streamlit

# 3. Variabile de mediu
echo "OPENAI_API_KEY=sk-..." > .env
```

**Cod minimal:**
```python
# agents/my_agent.py
from agents import Agent, function_tool, Runner
from pydantic import BaseModel

class MyOutput(BaseModel):
    answer: str
    confidence: float

@function_tool
def search_database(query: str) -> str:
    """Search the database."""
    return f"Results for: {query}"

my_agent = Agent(
    name="My Agent",
    instructions="Answer questions using the search tool.",
    tools=[search_database]
)

async def run_agent(question: str) -> MyOutput:
    result = await Runner.run(my_agent, question)
    return MyOutput.model_validate_json(result.final_output)
```

### OpÈ›iunea C: OpenAI SDK Direct (ca SpaceFlow)

**CÃ¢nd sÄƒ foloseÈ™ti:** CÃ¢nd vrei control complet fÄƒrÄƒ abstractions.

```bash
# 1. Init proiect FastAPI
mkdir my-api && cd my-api
python -m venv venv && source venv/bin/activate

# 2. Instalare
pip install openai fastapi uvicorn pydantic

# 3. Variabile de mediu
echo "OPENAI_API_KEY=sk-..." > .env
```

**Cod minimal:**
```python
# services/ai_service.py
from openai import AsyncOpenAI
import json

client = AsyncOpenAI()

async def get_suggestion(prompt: str) -> dict:
    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "Return JSON only."},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )
    return json.loads(response.choices[0].message.content)
```

---

## â­ Patterns È™i Best Practices

### 1. Separare MatematicÄƒ vs LLM

```
âœ… BUN: Calcule matematice ÃNAINTE de LLM
   - industrySaturation = calculateSaturation(data)
   - LLM primeÈ™te valorile calculate

âŒ RÄ‚U: LLM face calcule
   - "Calculate the saturation rate..."
```

### 2. Schema First

```
âœ… BUN: DefineÈ™te schema Ã®nainte de cod
   const MySchema = z.object({...})
   
âŒ RÄ‚U: Parsezi JSON fÄƒrÄƒ validare
   JSON.parse(response)
```

### 3. Timeout È™i Retry

```python
# SpaceFlow approach
client = AsyncOpenAI(timeout=120.0)

# Cu retry
from tenacity import retry, stop_after_attempt
@retry(stop=stop_after_attempt(3))
async def call_ai(...):
    ...
```

### 4. Logging È™i Debug

```python
print(f"[AI] Request: {prompt[:100]}...")
print(f"[AI] Response: {result}")
```

### 5. Cost Control

```
gpt-4o-mini: $0.15/$0.60 per 1M tokens (input/output)
gpt-4o:      $2.50/$10.00 per 1M tokens

â†’ FoloseÈ™te gpt-4o-mini pentru majoritatea task-urilor
â†’ gpt-4o doar pentru rapoarte complexe
```

---

## ğŸ“Š ComparaÈ›ie FinalÄƒ

| Aspect | Innovative4AI | NEXXT_AI | SpaceFlow |
|--------|---------------|----------|-----------|
| **Framework AI** | Vercel AI SDK | OpenAI Agents SDK | OpenAI Direct |
| **Complexitate** | High (9 agents) | High (13 agents) | Low (1 agent) |
| **RAG** | âœ… Qdrant | âŒ | âŒ |
| **Multi-Agent** | âœ… Orchestrator | âœ… Orchestrator | âŒ |
| **Streaming** | Posibil | Posibil | âŒ |
| **Provider Agnostic** | Partial | âœ… LiteLLM | âŒ OpenAI only |
| **Tools/Functions** | âŒ | âœ… function_tool | âŒ |
| **MCP** | âŒ | âœ… | âŒ |
| **Caz de utilizare** | SimulÄƒri complexe | AgenÈ›i modulari | API simple |

---

## ğŸš€ Quick Start Template

Pentru un proiect nou, recomand:

1. **Simple AI feature** â†’ SpaceFlow approach (OpenAI direct)
2. **Multi-agent system** â†’ NEXXT approach (Agents SDK)
3. **Complex orchestration + RAG** â†’ Innovative4AI approach (Vercel AI SDK + Qdrant)

**Template recomandat pentru Ã®nceput:**

```
my-ai-project/
â”œâ”€â”€ .env
â”œâ”€â”€ package.json / requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ schemas.ts / schemas.py
â”‚   â”‚   â”œâ”€â”€ agent-1.ts / agent_1.py
â”‚   â”‚   â””â”€â”€ orchestrator.ts / orchestrator.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ rag-service.ts (opÈ›ional)
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ routes/
â””â”€â”€ docker-compose.yml
```

---

**Document generat pe baza analizei celor 3 proiecte de hackathon.**
